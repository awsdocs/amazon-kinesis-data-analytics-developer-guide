# State skew<a name="troubleshooting-state-skew"></a>

For stateful operators, i\.e\., operators that maintain state for their business logic such as windows, data skew always leads to state skew\. Some subtasks receive more events than others because of the skew in the data and hence are also persisting more data in state\. However, even for an application that has evenly balanced partitions, there can be a skew in how much data is persisted in state\. For instance, for session windows, some users and sessions respectively may be much longer than others\. If the longer sessions happen to be part of the same partition, it can lead to an imbalance of the state size kept by different subtasks of the same operator\.

 State skew not only increases more memory and disk resources required by individual subtasks, it can also decrease the overall performance of the application\. When an application is taking a checkpoint or savepoint, the operator state is persisted to Amazon S3, to protect the state against node or cluster failure\. During this process \(especially with exactly once semantics that are enabled by default on Kinesis Data Analytics\), the processing stalls from an external perspective until the checkpoint/savepoint has completed\. If there is data skew, the time to complete the operation can be bound by a single subtask that has accumulated a particularly high amount of state\. In extreme cases, taking checkpoints/savepoints can fail because of a single subtask not being able to persist state\.

 So similar to data skew, state skew can substantially slow down an application\.

 To identify state skew, you can leverage the Flink dashboard\. Find a recent checkpoint or savepoint and compare the amount of data that has been stored for individual subtasks in the details\.